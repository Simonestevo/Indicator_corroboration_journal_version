---
title: "exploratory_data_analysis"
author: "Simone Stevenson"
date: "05/05/2021"
output:
  html_document: default
  pdf_document: default
---
# Setup
## TODO: Give plots captions
## TODO: Split up chunks with descriptors
## TODO: Remove any unused variables from main manuscript objects

```{r setup, include=FALSE}

# Using R version 4.0.3

## Clear the space
rm(list = ls()) # clear memory

# Load packages ----

# install.packages("tidyverse", dependencies = TRUE)
# install.packages("ggplot2", dependencies = TRUE)
# #install.packages("grid")
# install.packages("viridis", dependencies = TRUE)
# install.packages("png", dependencies = TRUE)
# install.packages("gridExtra", dependencies = TRUE)
# install.packages("reshape2", dependencies = TRUE)
# install.packages("GGally", dependencies = TRUE)
# install.packages("mapview", dependencies = TRUE)
# install.packages("psych", dependencies = TRUE)
# install.packages("e1071", dependencies = TRUE)
# install.packages("tm", dependencies = TRUE)
# install.packages("PerformanceAnalytics", dependencies = TRUE)

# TODO ----

#' TODO: Prepare stats summary for indicators and variables (or can use 
#' boxplots? add jitter?)
#' TODO: Split input prep from data visualisation
#' TODO: Remove superfluous steps
#' TODO: Make another folder called something like MS figures? for stuff that's
#' definitely going in
#' TODO: Fix ecoregion lookup function
#' TODO: Figure out cluster on princomp pl.pca object
#' TODO: Remove non-significant correlaitons (the ones whose CI pass zero) from
#' caterpillar plots
#' TODO: Rename grouping variables to categorical variables
#' TODO: Note the categorical independence matrices contain NAs because the combinations
#' are in the wrong order - not sure how to fix?

# PCA, Clustering, Models
library(corrplot)
library(ggpubr)

# Data handling and table reshaping
library(tidyverse)
library(tidylog)
library(reshape2)
library(devtools)
library(data.table)
library(rlist)
library(e1071)
library(psych)
library(arules)
library(ppsr)

# Plotting
library(ggplot2)
library(RColorBrewer)
library(viridis)
library(png)
library(ggcorrplot)
library(knitr)



# Set input and output locations ----

create_new_database_version <- FALSE # Only set to true if you want to create an entirely new version from scratch
date <- Sys.Date()
country <- NA #"Australia" # If not subsetting, set as NA, e.g. country <- NA
analysis_inputs <- "N:/Quantitative-Ecology/Simone/extinction_test/outputs/version_3/2020-08-25_indicator_output_files"
save_outputs <- "yes" #only applies to maps, other things will always save
eco_version <- "ecoregions_2017"
parent_outputs <- "N:/Quantitative-Ecology/Simone/extinction_test/outputs"
#eco_version <- "official_teow_wwf"
indicator_columns <- c("indicator", "year", "ecoregion_id", "raw_indicator_value")
timepoints <- c("2005", "2008")
load_map <- TRUE
indicators_to_remove <- c("RLIother", "RLILU")

# Set up some ecoregions that we know how they should behave

east_australia <- 168 # Decline over time
amazon <- 473 # Decline over time
cardamom <- 223 # In good shape
mascarene <- 20 #Had a lot of extinctions


if (!is.na(country)) {
  
  location <- tolower(country)
  
} else {
  
  location <- "global"
  
}

# Set output directory

db_version <- tail(sort(list.files(parent_outputs)), 1)
db_interim <- list.files(file.path(parent_outputs,db_version))[
  grepl("interim",list.files(file.path(parent_outputs,db_version)))]
db_outputs <- list.files(file.path(parent_outputs,db_version))[
  grepl("database",list.files(file.path(parent_outputs,db_version)))]
ind_outputs <- list.files(file.path(parent_outputs,db_version))[
  grepl("indicator",list.files(file.path(parent_outputs,db_version)))]
analysis_outputs <- list.files(file.path(parent_outputs,db_version))[
  grepl("analysis",list.files(file.path(parent_outputs,db_version)))]

interim_outputs <- file.path(parent_outputs, db_version, db_interim)
outputs <- file.path(parent_outputs, db_version, db_outputs)

if( (length(analysis_outputs)) == 0 ) {
  
  analysis_outputs <- file.path(parent_outputs, db_version, paste(date,
                                                                  "_analysis_output_files",sep="") )
  
  dir.create(analysis_outputs, recursive = TRUE ) # create a new directory for today's outputs
  
  
} else {
  
  analysis_outputs <- file.path(parent_outputs, db_version, analysis_outputs)
  
}

# # Create a folder for the day because you'll probably make lots of version
# 
# 
# current_analysis_outputs <- file.path(analysis_outputs,paste(date,
#                                                              "_analysis_output_files",sep=""))
# 
# dir.create(current_analysis_outputs)

# Folder for final manuscript figures

manuscript_outputs <- "N:\\Quantitative-Ecology\\Simone\\extinction_test\\outputs\\version_3\\2021-05-04_manuscript_outputs"
  
dir.create(manuscript_outputs, recursive = TRUE ) # create a new directory for today's outputs

todays_outputs <- file.path(manuscript_outputs, date)

dir.create(todays_outputs)

main_outputs <- file.path(todays_outputs, paste(date,
                                 "_main_manuscript_outputs",sep="") )
  
dir.create(main_outputs, recursive = TRUE )

# Folder for supporting info figures

supp_outputs <- file.path(todays_outputs, paste(date,
                                 "_supporting_info_outputs",sep="") )
  
dir.create(supp_outputs, recursive = TRUE )

# Folder for clean data

data_outputs <- file.path(todays_outputs, paste(date,
                                 "_data_outputs",sep="") )
  
dir.create(data_outputs, recursive = TRUE )


# Load functions ----

# Function to scale the values of a vector from 0 to 1

scale_to_1 <- function(vector){
  
  (vector-min(vector, na.rm = TRUE))/
    (max(vector, na.rm = TRUE)-min(vector, na.rm = TRUE))
}

add_grouping_variable <- function(variable, indicator_data, ecoregion_data) {
  
  out <- indicator_data %>%
    merge(ecoregion_data[c("ecoregion_id", variable)],
          by = "ecoregion_id") 
  
  return(out)
  
}

make_heatmap <- function(data) {
  
  heatmap <- ggplot(data, aes(x = subgroup,
                              y = combination,
                              fill = coefficient)) +
    geom_tile(color = "white") +
    geom_text(aes(label=coefficient), size = 2) +
    scale_fill_gradient2(limits = c(-1,1), low = "#453781FF", high = "#287D8EFF") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(x = paste(nice_grouping_variables[i],"ecoregion subgroups", sep = " "),
         y = "Pairwise indicator comparisons") +
    guides(fill = guide_legend(title = "Correlation\ncoefficient (r)")) +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "grey97"),
          legend.position = "bottom",
          axis.title.x = element_text(size=8),
          axis.title.y = element_text(size=8),
          axis.text.x = element_text(size= 7),
          axis.text.y = element_text(size= 7)) +
    facet_grid(ind_group ~., scales = "free_y") +
    theme(strip.text.x = element_text(size = 7, hjust = 0))
  
  heatmap <- heatmap +  scale_x_discrete(label = function(x) stringr::str_trunc(x, 28)) 
  
  return(heatmap)
  
}

lookup_ecoregion <- function(eco_id_number, data, map) {
  
  eco_name <- map %>% filter(ecoregion_id == eco_id_number) %>%
    dplyr::select(ecoregion_id, ECO_NAME) %>%
    st_drop_geometry()
  
  print(eco_name)
  
  eco_vals <- data %>% 
    filter(ecoregion_id == eco_id_number) %>%
    dplyr::select(all_of(indicators)) 
  
  averages <- data %>%
    dplyr::select(all_of(indicators)) %>%
    colMeans(na.rm = TRUE)
  
  id_col <- c(paste("eco", eco_id_number, "scores", sep = " "), "global_mean")
  eco_vals <- rbind(eco_vals, averages)
  
  eco_vals <- cbind(id_col, eco_vals)
  
  eco_vals
  
}

# matrix should be indicators as columns, rownames are eco_id
# group is string for group, subgroup is a string denoting the subgroup (eg mangroves)

make_subgroup_scatterplot <- function(df, group, subgroup, group_directory) {
  
  
  subgroup <- str_replace(subgroup, " - ", "_")
  subgroup <- str_replace(subgroup, " & ", "and")
  subgroup <- str_replace(subgroup, " , ", "_")
  subgroup <- str_replace(subgroup, " . ", "_")
  subgroup <- str_replace(subgroup, " ", "_")
  subgroup <- str_replace(subgroup, "/", "_")
  
  # Set rownames back to column
  # df <- tibble::rownames_to_column(df)
  # 
  # df <- df %>%
  #       dplyr::rename(ecoregion_id = rowname)
  
  ecoregion_id <- as.numeric(df$ecoregion_id)
  
  # Get all possible combinations of indicators from the df
  indicator_combos <- combn(names(df[-1]), 2)
  
  # Now loop through the combos
  i <- i + 1
  subgroup_scatterplots <- list()
  
  for (i in seq_along(1:ncol(indicator_combos))) {
    
    print(i)
    combo <- as.vector(indicator_combos[,i])
    
    print(combo)
    
    plotname <- paste(combo[1], combo[2], subgroup, sep = "_")
    
    plotname
    
    x_axis <- df[ , grepl( combo[1] , names( df ) ) ]
    range(x_axis)
    
    y_axis <- df[ , grepl( combo[2] , names( df ) ) ]
    range(y_axis)
    
    plot_df <- as.data.frame(cbind(ecoregion_id, x_axis, y_axis))
    
    scatterplot <- ggplot(plot_df, aes(x = x_axis, y = y_axis)) +
      geom_point() +
      labs(x = combo[1],
           y = combo[2]) + 
      stat_cor(method = "spearman") +
      ggtitle(paste(group, subgroup, sep = " - ")) +
      geom_text(label = plot_df$ecoregion_id, nudge_x = 0.1)
    
    ggsave(file.path(group_directory,
                     paste(plotname,
                           "scatterplot.png",
                           sep = "_")),
           scatterplot,  device = "png")
    
    subgroup_scatterplots[[i]] <- scatterplot
    
  }
  
  subgroup_scatterplots
  
}

```
# Prepare ecoregion data ----

```{r data prep, include = FALSE, message = FALSE, warning = FALSE}

raw_ecoregions_wide <- readRDS(file.path(analysis_inputs,
                                         "global_ecoregions_2017_ecoregion_values_master_wide.rds"))

# Keep a copy of unaltered ecoregion data

ecoregions_wide <- raw_ecoregions_wide 

names(ecoregions_wide) <- tolower(names(ecoregions_wide))

ecoregions_wide$area_factor <- discretize(ecoregions_wide$ecoregion_area_km_sq, 
                                          method = "frequency",
                                          breaks = 3, 
                                          labels = c("Small_ecoregions", 
                                                     "Medium_ecoregions",
                                                     "Large_ecoregions"),
                                          ordered_result = TRUE)

# Split the ecoregions by lpi data by fewer than 20 (minimum population sample
# required for SDMs) and more than 20

ecoregions_wide$lpi_records_factor <- cut(ecoregions_wide$lpi_records, 
                                          breaks = c(-Inf,19, Inf),
                                          labels = c("less than 20 lpi pops",
                                                     "more than 20 lpi pops"))

# Split ecoregions by RLI species fewer than 400 and more than 400 (based
# on min sample in Henriques et al 2020)

ecoregions_wide$rli_records_factor <- cut(ecoregions_wide$rli_records, 
                                          breaks = c(-Inf,400, Inf),
                                          labels = c("less than 400 rli spp",
                                                     "more than 400 rli spp"))
table(ecoregions_wide$rli_records_factor)

ecoregions_wide <- ecoregions_wide %>% 
  mutate(land_use = ifelse(included_in_hfp == 1, 
                                  "Land use",
                                  ifelse(included_in_hfp == 0,
                                         "Non land use",
                                         NA)))

ecoregions_wide$endemics_factor <- cut(ecoregions_wide$number_of_endemics, 
                                       breaks = c(-Inf, 0 , Inf),
                                       labels = c("no endemics",
                                                  "endemics"))


table(ecoregions_wide$endemics_factor)

ecoregions_wide$high_beta_area_factor <- discretize(ecoregions_wide$high_beta_area, 
                                                    method = "interval",
                                                    breaks = 4,
                                                    labels = c("very low beta",
                                                               "low beta",
                                                               "medium beta",
                                                               "high beta"))

table(ecoregions_wide$high_beta_area)

# Remove any unwanted grouping variables

names(ecoregions_wide)

ecoregions_wide <- ecoregions_wide %>%
  dplyr::select(-mean_scientific_publications,
                -headline_threat_type)

# Convert any characters into factors

ecoregions_wide <- ecoregions_wide %>% 
  mutate(across(where(is.character), as.factor)) 

# Add scaled/density variables

ecoregions_wide <- ecoregions_wide %>% 
  mutate(scaled_rli_records = rli_records/ecoregion_area_km_sq) %>% 
  mutate(scaled_lpi_records = lpi_records/ecoregion_area_km_sq,
         scaled_endemics = number_of_endemics/ecoregion_area_km_sq,
         scaled_threat_count = predominant_threat_count/rli_records)


# Get the names of factors

grouping_variables <- names(dplyr::select_if(ecoregions_wide, is.factor))

grouping_variables

# Get names of numeric variables 

numeric_variables <- names(dplyr::select_if(ecoregions_wide, is.numeric))
numeric_variables <- numeric_variables[!str_detect(numeric_variables, "ecoregion_id")]
numeric_variables

rm(raw_ecoregions_wide)

# Indicator data ----

# Indicator data

raw_indicators_long_all <- readRDS(file.path(analysis_inputs,
                                             "global_ecoregions_2017_indicator_values_master.rds"))

raw_indicators_long_all$indicator_year <- str_replace(raw_indicators_long_all$indicator_year, " ", "_")


raw_indicators_long <- raw_indicators_long_all %>%
  dplyr::select(ecoregion_id, indicator_year,
                raw_indicator_value) %>%
  distinct(.)

raw_indicators_wide <- raw_indicators_long %>%
  spread(key = indicator_year, 
         value = raw_indicator_value) 

dim(raw_indicators_wide)

raw_names <- names(raw_indicators_wide)
new_raw_names <- str_replace(raw_names, " ", "_")
names(raw_indicators_wide) <- new_raw_names

# Get single timepoint indicator names

# Get single timepoint indicators

indicators_05 <- names(raw_indicators_wide)[str_detect(names(raw_indicators_wide),
                                                       timepoints[[1]])]

indicators_08 <- names(raw_indicators_wide)[str_detect(names(raw_indicators_wide),
                                                       timepoints[[2]])]

# Remove LPI 2008 record which is the only indicator with timepoints for 05 and 08

indicators_08 <- indicators_08[!str_detect(indicators_08,
                                           "LPI_2008")]

indicators <- c(indicators_05, indicators_08)

# # Threat scheme
# 
# threat_scheme <- read.csv(file.path("N:/Quantitative-Ecology/Simone/extinction_test/inputs/iucn_threats\\iucn_threat_classification_scheme.csv"))
# 
# headline_threats <- threat_scheme %>%
#   dplyr::select(headline_name) %>%
#   distinct(.) %>%
#   pull()
# 
# headline_threats <- c(headline_threats, "All threats")

# # Ecoregion map ----
# 
# if(load_map == TRUE) {
#   
#   ecoregion_map_all <- readRDS(paste(
#     file.path("N:/Quantitative-Ecology/Simone/extinction_test/inputs",
#               "ecoregions_2017"),
#     "Ecoregions2017valid.rds"))
#   
#   ecoregion_map <- ecoregion_map_all %>%
#     dplyr::select(ECO_ID, ECO_NAME, OBJECTID, REALM, geometry)
#   
#   ecoregion_map_renamed <- ecoregion_map %>% dplyr::rename(ecoregion_id = ECO_ID)
#   
#   rm(ecoregion_map_all, ecoregion_map)
#   
# }
# 
# ecoregions <- ecoregion_map_renamed %>% 
#   st_drop_geometry()
# # Countries
# 
# ecoregion_countries <- readRDS(file.path(parent_outputs, "version_3",
#                                          "2020-08-10_database_output_files",
#                                          "ecoregion_country_data.rds"))

# Indicator data cleaning ----

# * Invert ----
# For negatively valanced variables (where high values = negative outcome)

negatives_index <- names(raw_indicators_wide) %like% 'HFP|extinct|threatened'
negatives <- names(raw_indicators_wide)[negatives_index]

cols_min <- as.numeric(sapply(raw_indicators_wide, min, na.rm = TRUE))
cols_max <- as.numeric(sapply(raw_indicators_wide, max, na.rm = TRUE))


keys <- as.data.frame(negatives_index) %>%
  mutate(keys = ifelse(negatives_index == FALSE, 1, -1)) %>%
  dplyr::select(keys) %>%
  pull(.)

indicators_wide <- as.data.frame(reverse.code(keys,raw_indicators_wide,
                                              mini = cols_min, maxi = cols_max))

dim(indicators_wide)

# * Fix column names ----

# Remove the little negative thing at the end of reversed column names, otherwise
# they become difficult to use with dplyr

names(indicators_wide) <- str_replace(names(indicators_wide), "-", "")

# Change full stops to underscores

names(indicators_wide) <- str_replace(names(indicators_wide), " ", "_")

indicators_all_timepoints <- names(indicators_wide)

indicators_all <- indicators_all_timepoints[!indicators_all_timepoints %in% 
                                              "ecoregion_id"]

# * Manage outliers ---- 

# A couple of big outliers in LPI values
hist(indicators_wide$LPI_2005, breaks = 20)
max(indicators_wide$LPI_2005, na.rm = TRUE)

# Get the 95th percentile

lpi_95 <- quantile(indicators_wide$LPI_2005, 
                   probs = 0.95, 
                   na.rm = TRUE)
lpi_95

lpi_mx_eco <- raw_indicators_wide %>%
  filter(LPI_2005 == max(LPI_2005, na.rm = TRUE)) %>%
  dplyr::select(ecoregion_id) %>%
  pull(.)

# Note, max positive LPI score goes to ecoregion 675 Po Basin, which also gets the third most
# negative (ie contradictory) score for HFP.  The three highest 
# values in the LPI had populations of 0 in 1970 and have since been colonised?

# ecoregion_map_renamed %>% filter(ecoregion_id == lpi_mx_eco)

# Just remove LPI outliers, given we know it is a dodgier dataset and volatile
indicators_wide_2 <- indicators_wide %>%
  mutate(LPI_2005 = ifelse(LPI_2005 > lpi_95,
                           NA, LPI_2005)) 

dim(indicators_wide_2)
max(indicators_wide_2$LPI_2005, na.rm = TRUE)
hist(indicators_wide_2$LPI_2005, breaks = 20)

# HFP values - have a couple of exceptionally low values

hist(indicators_wide$HFP_2005, breaks = 20)
min(indicators_wide$HFP_2005, na.rm = TRUE)
hfp_mx <- max(raw_indicators_wide$HFP_2005, na.rm = TRUE)
hfp_mx_eco <- raw_indicators_wide %>%
  filter(HFP_2005 == max(HFP_2005, na.rm = TRUE)) %>%
  dplyr::select(ecoregion_id) %>%
  pull(.)

# Looking at HFP map, bermuda cells do have very high scores (eg 48), which
# matches with the ecoregions WWF description of severe degradation, so
# don't remove outliers

# lookup_ecoregion(hfp_mx_eco)

# Extinctions also have some very high values, however these can be verified and are
# correct, so don't remove

hist(indicators_wide$extinct_2008, breaks = 20)
min(indicators_wide$extinct_2008, na.rm = TRUE)

# * Remove unwanted indicators ----

saveRDS(indicators_wide_2, file.path(data_outputs, "0_indicators_all_timepoints.rds"))
write.csv(indicators_wide_2, file.path(data_outputs, "0_indicators_all_timepoints.csv"))

indicators_cleaned <- indicators_wide_2 %>%
  dplyr::select(-number_extinct_2008, -number_extinct_2016,
                -AmphRLI_2008, -BirdRLI_2008, -BirdRLI_2016,
                -MammRLI_2008)

dim(indicators_cleaned)

# Get complete cases only (with LPI)

indicators_cleaned_2005_lpi <- indicators_cleaned %>% 
                           dplyr::select(ecoregion_id, BHI_plants_2005,
                                         BIIab_2005, BIIri_2005, HFP_2005,
                                         LPI_2005, extinct_2008, RLI_2008,
                                         threatened_2008)
  
  
indicators_correlation_input_lpi <- indicators_cleaned_2005_lpi[complete.cases(
  indicators_cleaned_2005_lpi),]

saveRDS(indicators_correlation_input_lpi, file.path(data_outputs, "1_indicators_cleaned_lpi.rds"))
write.csv(indicators_correlation_input_lpi, file.path(data_outputs, "1_indicators_cleaned_lpi.csv"))

indicator_correlation_matrix_lpi <- cor(indicators_correlation_input_lpi, 
                                     method = "spearman")

# Save correlaiton matrix for reference but don't print

saveRDS(indicator_correlation_matrix_lpi,
        file.path(supp_outputs, "indicator_correlation_matrix_lpi.RDS"))

write.csv(indicator_correlation_matrix_lpi,
          file.path(supp_outputs, "indicator_correlation_matrix_lpi.csv"))

# Get complete cases only (without LPI)

indicators_cleaned_2005 <- indicators_cleaned %>% 
  dplyr::select(ecoregion_id, BHI_plants_2005,
                BIIab_2005, BIIri_2005, HFP_2005,
                extinct_2008, RLI_2008,
                threatened_2008)


indicators_correlation_input <- indicators_cleaned_2005[complete.cases(
  indicators_cleaned_2005),]

saveRDS(indicators_correlation_input, file.path(data_outputs, "2_indicators_cleaned_no_lpi.rds"))
write.csv(indicators_correlation_input, file.path(data_outputs, "2_indicators_cleaned_no_lpi.csv"))


# Make and save the summary table

final_indicators <- c("BHI_plants_2005", "BIIab_2005", "BIIri_2005", "HFP_2005", 
                      "extinct_2008", "RLI_2008", "threatened_2008")


indicators_long <- indicators_cleaned_2005 %>% 
                   pivot_longer(final_indicators)

indicators_summary <- indicators_long %>% 
                      group_by(name) %>% 
                      summarise(min = min(value, na.rm = TRUE),
                                median = median(value, na.rm = TRUE),
                                mean = mean(value, na.rm = TRUE),
                                max = max(value, na.rm = TRUE))

write.csv(indicators_summary,
          file.path(main_outputs, "indicator_summary_table.csv"))

indicator_correlation_matrix <- cor(indicators_correlation_input, 
                                        method = "spearman")

# Save correlaiton matrix for reference but don't print

saveRDS(indicator_correlation_matrix,
        file.path(supp_outputs, "indicator_correlation_matrix.RDS"))

write.csv(indicator_correlation_matrix,
          file.path(supp_outputs, "indicator_correlation_matrix.csv"))


# ## Save the cleaned indicator data
# 
# saveRDS(indicators_cleaned,
#         file.path(data_outputs, "indicators_cleaned.RDS"))
# 
# write.csv(indicators_cleaned,
#           file.path(data_outputs, "indicators_cleaned.csv"))

# ggplot(indicators_cleaned, aes(x = BHI_plants_2005, 
#                                y = RLI_2008)) +
#   geom_point() +
#   geom_text(label = indicators_cleaned$ecoregion_id) + 
#   stat_cor(method = "spearman")
# 
# ggplot(indicators_cleaned, aes(x = BIIri_2005, 
#                                y = RLI_2008)) +
#   geom_point() +
#   geom_text(label = indicators_cleaned$ecoregion_id) + 
#   stat_cor(method = "spearman")
# 
# ggplot(indicators_cleaned, aes(x = HFP_2005, 
#                                y = RLI_2008)) +
#   geom_point() +
#   geom_text(label = indicators_cleaned$ecoregion_id) + 
#   stat_cor(method = "spearman")
# 
# ggplot(indicators_cleaned, aes(x = BHI_plants_2005, 
#                                y = BIIri_2005)) +
#   geom_point() +
#   geom_text(label = indicators_cleaned$ecoregion_id) + 
#   stat_cor(method = "spearman")

# * standardise ----

indicators_wide_standardised <- indicators_wide_2 %>%
  mutate_at(c(2:ncol(indicators_wide_2)), 
            funs(c(scale(.)))) 

summary(indicators_wide_standardised)

```

# Indicator Boxplots

```{r boxplots, echo=FALSE, warning = FALSE, message = FALSE}
# ** Centred boxplots ----

#' IMPORTANT - this boxplot shows with outliers already removed

# Get 2005 only
indicator_boxplot_data_wide <- indicators_wide_standardised %>%
  dplyr::select(all_of(c("ecoregion_id", final_indicators)))

saveRDS(indicator_boxplot_data_wide, file.path(data_outputs, "3_indicators_cleaned_standardised_no_lpi.rds"))
write.csv(indicator_boxplot_data_wide, file.path(data_outputs, "3_indicators_cleaned_standardised_no_lpi.csv"))

indicator_boxplot_data_wide_lpi <- indicators_wide_standardised %>%
  dplyr::select(all_of(c("ecoregion_id", final_indicators, "LPI_2005")))

saveRDS(indicator_boxplot_data_wide_lpi, file.path(data_outputs, "4_indicators_cleaned_standardised_lpi.rds"))
write.csv(indicator_boxplot_data_wide_lpi, file.path(data_outputs, "4_indicators_cleaned_standardised_lpi.csv"))


# Convert back into long format
indicator_boxplot_data <- reshape2::melt(indicator_boxplot_data_wide, 
                                         id.vars = 'ecoregion_id')

# saveRDS(indicator_boxplot_data, file.path(data_outputs, "indicator_boxplot_data.rds"))
# write.csv(indicator_boxplot_data, file.path(data_outputs, "indicator_boxplot_data.csv"))

boxplots <- ggplot(indicator_boxplot_data,aes(x = variable, y = value)) +
  geom_boxplot() +
  #geom_point(position = "jitter",alpha = 0.1) +
  theme(axis.text.x = element_text(angle= 45,hjust=1)) +
  geom_hline(yintercept = 0) +
  theme(
    legend.position = "none",
    axis.text.y = element_text(size = 6),
    axis.text.x = element_text(size = 6))+
  xlab("Indicator") + ylab("Indicator value")


ggsave(file.path(main_outputs , "indicator_boxplots.png"),
       boxplots, device = "png")

rm(raw_indicators_wide)
rm(indicator_boxplot_data)

# Ecoregion summaries

ecoregions_numeric <- ecoregions_wide[,c("ecoregion_id", numeric_variables)]

saveRDS(ecoregions_numeric, file.path(data_outputs, "5_ecoregions_numeric.rds"))
write.csv(ecoregions_numeric, file.path(data_outputs, "5_ecoregions_numeric.csv"))

ecoregions_numeric_long <- ecoregions_numeric %>% 
                           pivot_longer(numeric_variables)

ecoregions_summary <- ecoregions_numeric_long %>% 
                      group_by(name) %>% 
                      summarise(min = min(value, na.rm = TRUE),
                                median = median(value, na.rm = TRUE),
                                mean = mean(value, na.rm = TRUE),
                                max = max(value, na.rm = TRUE))

write.csv(ecoregions_summary,
          file.path(main_outputs, "ecoregion_summary_table.csv"))

# Categorical tables

ecoregions_categorical <- ecoregions_wide[,c("ecoregion_id", grouping_variables)]

saveRDS(ecoregions_categorical, file.path(data_outputs, "7_ecoregions_categorical.rds"))
write.csv(ecoregions_categorical, file.path(data_outputs, "7_ecoregions_categorical.csv"))


categorical_tables <- apply(ecoregions_categorical, 2, table)

# Make boxplots

## Standardize

ecoregions_numeric_standardized <- ecoregions_numeric %>%
  mutate_at(c(2:ncol(ecoregions_numeric)), 
            funs(c(scale(.)))) 

saveRDS(ecoregions_numeric_standardized, file.path(data_outputs, "6_ecoregions_numeric_standardized.rds"))
write.csv(ecoregions_numeric_standardized, file.path(data_outputs, "6_ecoregions_numeric_standardized.csv"))

ecoregion_boxplot_data <- reshape2::melt(ecoregions_numeric_standardized, 
                                         id.vars = 'ecoregion_id')

eco_boxplots <- ggplot(ecoregion_boxplot_data,aes(x = variable, y = value)) +
  geom_boxplot() +
  #geom_point(position = "jitter",alpha = 0.1) +
  theme(axis.text.x = element_text(angle= 45,hjust=1)) +
  geom_hline(yintercept = 0) +
  theme(
    legend.position = "none",
    axis.text.y = element_text(size = 6),
    axis.text.x = element_text(size = 6))+
  xlab("Variable") + ylab("Ecoregion variable value")


ggsave(file.path(main_outputs , "eco_boxplots.png"),
       boxplots, device = "png")

barplot_data <- reshape2::melt(ecoregions_wide, measure.vars = grouping_variables)

barplot_data <- barplot_data %>% 
                rename(group = variable,
                 subgroup = value) %>%
                 group_by(group, subgroup) %>%
                 summarise(ecoregion_count = n_distinct(ecoregion_id)) %>%
                 ungroup()

group_barplot_data <- split(barplot_data, barplot_data$group)
length(group_barplot_data)

# Make the individual barplots for each grouping variable

barplots <- list()

for ( i in seq_along(group_barplot_data)) {
  
  barplots[[i]] <- ggplot(group_barplot_data[[i]]) +
    geom_col(aes(x = group, 
                 y = ecoregion_count,
                 fill = subgroup), 
             position = "fill") +
    facet_wrap(~ group)  +
    theme(strip.text.x = element_text(size = 10),
          axis.text.x = element_text(size = 8),
          legend.position = "bottom",
          legend.text = element_text(size = 8),
          axis.ticks = element_blank()) +
    xlab("Cluster") + 
    ylab("Ecoregion categories") + 
    labs(color ='Ecoregion categories') +
    scale_fill_viridis(discrete=TRUE) +
    scale_color_viridis(discrete=TRUE) 
  
}

barplots

```
# Numeric

```{r numeric, echo=FALSE, warning = FALSE, message = FALSE}

# * Check explanatory variables for collinearity ----

## ** Numeric ----

ecoregions_collinear_inputs <- as.matrix(ecoregions_wide[,numeric_variables])

ecoregions_collinear_inputs <- ecoregions_collinear_inputs[complete.cases(
  ecoregions_collinear_inputs),]

ecoregions_correlation_matrix <- cor(ecoregions_collinear_inputs, 
                                     method = "spearman")

# *** PRINT COLLINEARITY TESTS ----

kable(ecoregions_correlation_matrix)


saveRDS(ecoregions_correlation_matrix,
        file.path(supp_outputs, "ecoregion_numerical_correlations.RDS"))

write.csv(ecoregions_correlation_matrix,
          file.path(supp_outputs, "ecoregion_numerical_correlations.csv"))


indicators_ecoregions <- indicators_cleaned_2005 %>% 
                         merge(ecoregions_numeric, by = "ecoregion_id")

indicators_ecoregions <- indicators_ecoregions[complete.cases(
  indicators_ecoregions),]

indicators_ecoregions_correlation_matrix <- cor(indicators_ecoregions, method = "spearman")

kable(indicators_ecoregions_correlation_matrix)

write.csv(indicators_ecoregions_correlation_matrix,
          file.path(supp_outputs, "indicators_ecoregions_correlation_matrix"))

```

# Categorical

```{r, echo=FALSE, warning = FALSE, message = FALSE}
# ** Categorical -----

# Remove incomplete rows
ecoregions_wide_complete <- ecoregions_wide[complete.cases(ecoregions_wide),]

ecoregions_wide_complete<- ecoregions_wide_complete %>% 
  mutate(area_factor = factor(ecoregions_wide_complete$area_factor, 
                              ordered = FALSE))

# Subset to only categorical variables

ecoregions_chisq_inputs <- ecoregions_wide[,grouping_variables]

# Select rows with complete data for all variables

ecoregions_chisq_inputs <- ecoregions_chisq_inputs[complete.cases(
  ecoregions_chisq_inputs),]


ecoregions_chisq_inputs <- ecoregions_chisq_inputs %>% mutate_if(is.character,as.factor)

# Get all possible combinations of variables

categorical_combinations <- combn(names(ecoregions_chisq_inputs), 2)

# https://statsandr.com/blog/chi-square-test-of-independence-in-r/

chisq_results <- list() # list to catch results of independence test
chi_residual_plots <- list(0) # list to catch correlation plot for each combo

for (i in 1:ncol(categorical_combinations)) {
  
  combo <- categorical_combinations[,i]
  
 #  print(paste("testing",combo[1], "and", combo[2], "for independence", sep = " "))
  
  test_inputs <- table(pull(ecoregions_chisq_inputs[, combo[1]]), # Get the two variables to test
                       pull(ecoregions_chisq_inputs[, combo[2]]))
  
  chi_result <- tryCatch(chisq.test(test_inputs,
                                    simulate.p.value = TRUE,
                                    B = 10000),
                         error=function(e) e, warning=function(w) w)
  
  # If the chi sq test throws a warning bc of small values, do fisher test instead
  
  if(is(chi_result,"warning")) { 
    
   # print( "Values too small for chi-square test, performing fisher test instead")
    
    fisher_result <- fisher.test(test_inputs, simulate.p.value = TRUE, B = 10000)
    
    # Make nice df result
    
    result <- cbind(combo[1], combo[2], fisher_result$p.value, NA, 
                    fisher_result$method)
    
  } else {
    
    result <- cbind(combo[1], combo[2], chi_result$p.value, 
                    chi_result$statistic, chi_result$method)
    
    # Plot the contingency table correlation for all subgroups (shows which 
    # subgroups contribute most to the result of independent or related)
    
    corrplot(chi_result$residuals, method = "circle",is.cor = FALSE, tl.cex = 0.8)
    
  }
  
  chisq_results[[i]] <- result
  
  #chi_residual_plots[[i]] <- plot
  
}

# Format the results into a nice dataframe and save

categorical_independence_results <- as.data.frame(do.call(rbind, chisq_results))

names(categorical_independence_results) <- c("var1", "var2", "p_value", 
                                             "statistic", "method")

# Convert characters back to numeric (needed for sorting in next step)

categorical_independence_results$p_value <- as.numeric(categorical_independence_results$p_value)
categorical_independence_results$statistic <- as.numeric(categorical_independence_results$statistic)

independent_categoricals <- categorical_independence_results %>% 
  filter(p_value >= 0.05) %>% 
  mutate(status = "independent") %>% 
  arrange(desc(statistic))

dependent_categoricals <- categorical_independence_results %>% 
  filter(p_value < 0.05) %>% 
  mutate(status = "correlated") %>% 
  arrange(desc(statistic))

# Save the outputs in tidy format

categorical_independence_output <- rbind(independent_categoricals,
                                         dependent_categoricals)

write.csv(categorical_independence_output,
          file.path(supp_outputs, "ecoregion_categorical_correlations.csv"))

# *** PRINT CATEGORICAL INDEPENDENCE TESTs ----

# Table

kable(categorical_independence_output)

# # Plot
# 
# walk(chi_residual_plots, print)
# 
# chi_residual_plots

# Make a matrix of chi square statistic values

chi_sq_matrix_stat <- categorical_independence_output %>% 
  dplyr::select(var1, var2, statistic) %>% 
  pivot_wider(names_from = var2, values_from = statistic,
              id_cols = c(var1,var2))

write.csv(chi_sq_matrix_stat,
          file.path(supp_outputs, "chi_sq_statistic_matrix.csv"))

# Make a matrix of independence status

# x <- unique(categorical_independence_output$var1)
# 
# chi_sq_matrix_pval <- categorical_independence_output %>% 
#   dplyr::select(var1, var2, status) %>%
#   pivot_longer(names_from = var2, values_from = status,
#                names_sort = TRUE)
# 
# write.csv(chi_sq_matrix_pval,
#           file.path(collinearity_outputs, "chi_sq_pvalue_matrix.csv"))

```

# ** Numeric vs categorical ----

```{r numeric vs categorical, echo=FALSE, warning = FALSE, message = FALSE }
# Get all the column names except ecoregion ID,so we can convert to long format
ecoregion_variables <- names(ecoregions_wide_complete)[!str_detect(names(
  ecoregions_wide_complete), "ecoregion_id")]

# Convert it to wide format so we can plot

ecoregions_long <- ecoregions_wide_complete %>% 
  pivot_longer(all_of(grouping_variables)) %>% 
  rename(group = name,
         subgroup = value)

# Split data by grouping variables

ecoregions_list <- split(ecoregions_long, 
                         ecoregions_long$group)

# Create empty lists to catch output

# by categorical grouping variable
ecoregion_groups <- list()

# by numeric grouping variable
group_numerics <- list()

for ( i in seq_along(ecoregions_list)) {
  
  # Get the data for a single grouping variable
  
  data <- ecoregions_list[[i]]
  
  group_name <- names(ecoregions_list)[[i]]
  
  for(j in seq_along(numeric_variables)) {
    
    # Plot each numeric variable on the y axis, against boxplots of the different
    # factor levels on the x axis
    
    plotname <- paste(group_name, "x", numeric_variables[[j]], "boxplot.png", 
                      sep = "_")
    
    group_numerics[[j]] <- ggplot(data,aes_string(x = "subgroup", 
                                                  y = numeric_variables[[j]])) +
      geom_boxplot() +
      # geom_point(position = "jitter",alpha = 0.1) +
      theme(axis.text.x = element_text(angle= 45,hjust=1)) +
      geom_hline(yintercept = 0) +
      theme(
        legend.position = "none",
        axis.text.y = element_text(size = 6),
        axis.text.x = element_text(size = 6))+
      xlab(group_name) + ylab(numeric_variables[[j]]) 
    
    ggsave(file.path(supp_outputs, plotname),
           group_numerics[[j]],
           device = "png")
    
  }
  
  ecoregion_groups[[i]] <- group_numerics
  
}

# i <- i + 1
# 
# j <- 1
# ecoregion_groups[[i]][[j]]
# 
# j <- j + 1
# ecoregion_groups[[i]][[j]]

walk(ecoregion_groups, print)

```